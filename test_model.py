"""
æ¸¬è©¦è¨“ç·´å¥½çš„ç³»å¤–è¡Œæ˜Ÿæª¢æ¸¬æ¨¡å‹
"""

import numpy as np
import pandas as pd
import joblib
from pathlib import Path
import json


class ExoplanetPredictor:
    """ç³»å¤–è¡Œæ˜Ÿé æ¸¬å™¨"""
    
    def __init__(self, model_path):
        """è¼‰å…¥æ¨¡å‹"""
        print(f"ğŸ“¥ è¼‰å…¥æ¨¡å‹: {model_path}")
        
        model_data = joblib.load(model_path)
        
        # è™•ç†ä¸åŒçš„æ¨¡å‹æ ¼å¼
        if 'model' in model_data:
            # æ¨™æº–æ ¼å¼ï¼šå–®ä¸€æ¨¡å‹
            self.model = model_data['model']
        elif 'target_model' in model_data:
            # Transfer learning æ ¼å¼ï¼šä½¿ç”¨ç›®æ¨™æ¨¡å‹
            self.model = model_data['target_model']
            if self.model is None:
                print("âš ï¸  ç›®æ¨™æ¨¡å‹ç‚ºç©ºï¼Œä½¿ç”¨æºæ¨¡å‹")
                self.model = model_data['source_model']
        elif 'source_model' in model_data:
            # Transfer learning æ ¼å¼ï¼šåªæœ‰æºæ¨¡å‹
            self.model = model_data['source_model']
        else:
            raise ValueError("ç„¡æ³•è­˜åˆ¥çš„æ¨¡å‹æ ¼å¼")
        
        self.scaler = model_data['scaler']
        self.label_encoder = model_data['label_encoder']
        
        # ç‰¹å¾µåˆ—è¡¨å¯èƒ½æœ‰ä¸åŒçš„éµå
        if 'selected_features' in model_data:
            self.selected_features = model_data['selected_features']
        elif 'feature_cols' in model_data:
            self.selected_features = model_data['feature_cols']
        else:
            raise ValueError("æ‰¾ä¸åˆ°ç‰¹å¾µåˆ—è¡¨")
        
        self.version = model_data.get('version', 'unknown')
        self.data_source = model_data.get('data_source', 'unknown')
        
        print(f"âœ“ æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        print(f"  ç‰ˆæœ¬: {self.version}")
        print(f"  è³‡æ–™ä¾†æº: {self.data_source}")
        print(f"  ç‰¹å¾µæ•¸: {len(self.selected_features)}")
        print(f"  é¡åˆ¥: {list(self.label_encoder.classes_)}")
    
    def prepare_features(self, df):
        """æº–å‚™ç‰¹å¾µ - æ”¯æ´ TESS å’Œ Kepler è³‡æ–™é›†"""
        
        # TESS å’Œ Kepler æ¬„ä½å°æ‡‰
        feature_mapping = {
            # TESS æ¬„ä½
            'Period (days)': 'period',
            'Duration (hours)': 'duration',
            'Depth (ppm)': 'depth',
            'Planet Radius (R_Earth)': 'planet_radius',
            'Planet Equil Temp (K)': 'equil_temp',
            'Planet Insolation (Earth Flux)': 'insolation',
            'Planet SNR': 'snr',
            'Stellar Eff Temp (K)': 'stellar_temp',
            'Stellar Radius (R_Sun)': 'stellar_radius',
            'Stellar log(g) (cm/s^2)': 'stellar_logg',
            'Stellar Mass (M_Sun)': 'stellar_mass',
            'TESS Mag': 'tess_mag',
            'Stellar Distance (pc)': 'distance',
            # Kepler æ¬„ä½
            'koi_period': 'period',
            'koi_duration': 'duration',
            'koi_depth': 'depth',
            'koi_prad': 'planet_radius',
            'koi_teq': 'equil_temp',
            'koi_insol': 'insolation',
            'koi_model_snr': 'snr',
            'koi_steff': 'stellar_temp',
            'koi_srad': 'stellar_radius',
            'koi_slogg': 'stellar_logg',
            'koi_smass': 'stellar_mass',
            'koi_kepmag': 'tess_mag',  # æ˜ å°„åˆ°ç›¸åŒç‰¹å¾µå
            'koi_dist': 'distance'
        }
        
        # å»ºç«‹ç‰¹å¾µçŸ©é™£
        available_features = {}
        for orig_name, new_name in feature_mapping.items():
            if orig_name in df.columns:
                if new_name not in available_features:  # é¿å…é‡è¤‡
                    available_features[orig_name] = new_name
        
        if not available_features:
            raise ValueError("æ‰¾ä¸åˆ°ä»»ä½•å¯ç”¨çš„ç‰¹å¾µæ¬„ä½")
        
        X = df[list(available_features.keys())].copy()
        X.columns = list(available_features.values())
        
        # è™•ç†ç¼ºå¤±å€¼ï¼ˆç”¨ä¸­ä½æ•¸å¡«è£œï¼‰
        for col in X.columns:
            if X[col].isnull().any():
                X[col].fillna(X[col].median(), inplace=True)
        
        # è¡ç”Ÿç‰¹å¾µ
        if 'period' in X.columns and 'duration' in X.columns:
            X['duration_period_ratio'] = X['duration'] / (X['period'] * 24 + 1e-6)
        
        if 'depth' in X.columns and 'planet_radius' in X.columns:
            X['depth_radius_ratio'] = X['depth'] / (X['planet_radius'] ** 2 + 1e-6)
        
        if 'snr' in X.columns:
            X['log_snr'] = np.log1p(X['snr'])
        
        if 'equil_temp' in X.columns and 'insolation' in X.columns:
            X['temp_insol_ratio'] = X['equil_temp'] / (X['insolation'] + 1e-6)
        
        if 'stellar_temp' in X.columns and 'stellar_radius' in X.columns:
            X['stellar_luminosity'] = (X['stellar_radius'] ** 2) * ((X['stellar_temp'] / 5778) ** 4)
        
        # ç§»é™¤ç„¡é™å€¼
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        # è£œé½Šæ¨¡å‹éœ€è¦ä½†ç¼ºå¤±çš„ç‰¹å¾µ
        for feat in self.selected_features:
            if feat not in X.columns:
                X[feat] = 0  # ç¼ºå¤±ç‰¹å¾µç”¨0å¡«å……
        
        # åªé¸æ“‡æ¨¡å‹éœ€è¦çš„ç‰¹å¾µï¼Œä¸¦ä¿æŒé †åº
        X_selected = X[self.selected_features]
        
        return X_selected
    
    def predict(self, X):
        """é€²è¡Œé æ¸¬"""
        # æ¨™æº–åŒ–
        X_scaled = self.scaler.transform(X)
        
        # é æ¸¬
        predictions = self.model.predict(X_scaled)
        probabilities = self.model.predict_proba(X_scaled)
        
        # è§£ç¢¼æ¨™ç±¤
        predicted_labels = self.label_encoder.inverse_transform(predictions)
        
        return predicted_labels, probabilities
    
    def predict_single(self, features_dict):
        """é æ¸¬å–®ç­†è³‡æ–™"""
        df = pd.DataFrame([features_dict])
        X = self.prepare_features(df)
        labels, probs = self.predict(X)
        
        return labels[0], probs[0]


def test_on_file(model_path, test_file):
    """æ¸¬è©¦æ•´å€‹æª”æ¡ˆ"""
    print("\n" + "="*60)
    print("ğŸ“Š æ‰¹æ¬¡æ¸¬è©¦")
    print("="*60)
    
    # è¼‰å…¥æ¨¡å‹
    predictor = ExoplanetPredictor(model_path)
    
    # è¼‰å…¥æ¸¬è©¦è³‡æ–™
    print(f"\nğŸ“¥ è¼‰å…¥æ¸¬è©¦è³‡æ–™: {test_file}")
    df = pd.read_csv(test_file)
    print(f"âœ“ æ¸¬è©¦è³‡æ–™: {df.shape}")
    
    # æº–å‚™ç‰¹å¾µ
    print("\nğŸ”§ æº–å‚™ç‰¹å¾µ...")
    X = predictor.prepare_features(df)
    print(f"âœ“ ç‰¹å¾µæº–å‚™å®Œæˆ: {X.shape}")
    
    # é æ¸¬
    print("\nğŸ¯ é€²è¡Œé æ¸¬...")
    labels, probs = predictor.predict(X)
    
    # åŠ å…¥çµæœåˆ° DataFrame
    df['predicted_class'] = labels
    for i, class_name in enumerate(predictor.label_encoder.classes_):
        df[f'prob_{class_name}'] = probs[:, i]
    
    # é¡¯ç¤ºçµæœæ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“ˆ é æ¸¬çµæœæ‘˜è¦")
    print("="*60)
    print(f"\né æ¸¬é¡åˆ¥åˆ†ä½ˆ:")
    print(df['predicted_class'].value_counts())
    
    # å¦‚æœæœ‰çœŸå¯¦æ¨™ç±¤ï¼Œè¨ˆç®—æº–ç¢ºç‡
    if 'TESS Disposition' in df.columns:
        # åˆä½µæ¨™ç±¤ï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒï¼‰
        label_mapping = {
            'KP': 'PLANET', 'CP': 'PLANET', 'PC': 'PLANET',
            'EB': 'FALSE_POSITIVE', 'FP': 'FALSE_POSITIVE',
            'IS': 'OTHER', 'V': 'OTHER', 'O': 'OTHER'
        }
        df['true_class'] = df['TESS Disposition'].map(label_mapping)
        
        # è¨ˆç®—æº–ç¢ºç‡
        correct = (df['predicted_class'] == df['true_class']).sum()
        total = len(df)
        accuracy = correct / total
        
        print(f"\næº–ç¢ºç‡: {accuracy:.2%} ({correct}/{total})")
        
        # æ··æ·†çŸ©é™£
        from sklearn.metrics import confusion_matrix, classification_report
        print("\nåˆ†é¡å ±å‘Š:")
        print(classification_report(df['true_class'], df['predicted_class']))
    
    # å„²å­˜çµæœ
    output_file = "predictions_output.csv"
    df.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ é æ¸¬çµæœå·²å„²å­˜: {output_file}")
    
    # é¡¯ç¤ºå¹¾å€‹ç¯„ä¾‹
    print("\n" + "="*60)
    print("ğŸ“‹ é æ¸¬ç¯„ä¾‹ (å‰ 10 ç­†)")
    print("="*60)
    
    display_cols = ['TOI', 'predicted_class'] + [f'prob_{c}' for c in predictor.label_encoder.classes_]
    if 'true_class' in df.columns:
        display_cols.insert(2, 'true_class')
    
    print(df[display_cols].head(10).to_string(index=False))
    
    return df


def test_single_example(model_path):
    """æ¸¬è©¦å–®ç­†ç¯„ä¾‹"""
    print("\n" + "="*60)
    print("ğŸ”¬ å–®ç­†æ¸¬è©¦")
    print("="*60)
    
    # è¼‰å…¥æ¨¡å‹
    predictor = ExoplanetPredictor(model_path)
    
    # ç¯„ä¾‹è³‡æ–™ï¼ˆä½ å¯ä»¥ä¿®æ”¹é€™äº›å€¼ï¼‰
    example = {
        'Period (days)': 3.5,
        'Duration (hours)': 2.5,
        'Depth (ppm)': 5000,
        'Planet Radius (R_Earth)': 1.2,
        'Planet Equil Temp (K)': 1200,
        'Planet Insolation (Earth Flux)': 400,
        'Planet SNR': 25,
        'Stellar Eff Temp (K)': 5800,
        'Stellar Radius (R_Sun)': 1.1,
        'Stellar log(g) (cm/s^2)': 4.4,
        'Stellar Mass (M_Sun)': 1.0,
        'TESS Mag': 10.5,
        'Stellar Distance (pc)': 200
    }
    
    print("\nè¼¸å…¥ç‰¹å¾µ:")
    for key, value in example.items():
        print(f"  {key}: {value}")
    
    # é æ¸¬
    label, probs = predictor.predict_single(example)
    
    print(f"\né æ¸¬çµæœ:")
    print(f"  é¡åˆ¥: {label}")
    print(f"  æ©Ÿç‡åˆ†ä½ˆ:")
    for i, class_name in enumerate(predictor.label_encoder.classes_):
        print(f"    {class_name}: {probs[i]:.2%}")
    
    return label, probs


def interactive_test(model_path):
    """äº’å‹•å¼æ¸¬è©¦"""
    print("\n" + "="*60)
    print("ğŸ’¬ äº’å‹•å¼æ¸¬è©¦")
    print("="*60)
    
    predictor = ExoplanetPredictor(model_path)
    
    print("\nè«‹è¼¸å…¥ç³»å¤–è¡Œæ˜Ÿå€™é¸çš„åƒæ•¸ï¼ˆæŒ‰ Enter ä½¿ç”¨é è¨­å€¼ï¼‰:")
    
    features = {}
    defaults = {
        'Period (days)': 3.5,
        'Duration (hours)': 2.5,
        'Depth (ppm)': 5000,
        'Planet Radius (R_Earth)': 1.2,
        'Planet SNR': 25,
        'Stellar Eff Temp (K)': 5800,
        'Stellar Radius (R_Sun)': 1.1
    }
    
    for key, default in defaults.items():
        try:
            value = input(f"{key} (é è¨­={default}): ").strip()
            features[key] = float(value) if value else default
        except:
            features[key] = default
    
    # è£œå……å…¶ä»–æ¬„ä½ï¼ˆä½¿ç”¨é è¨­å€¼ï¼‰
    features.update({
        'Planet Equil Temp (K)': 1200,
        'Planet Insolation (Earth Flux)': 400,
        'Stellar log(g) (cm/s^2)': 4.4,
        'Stellar Mass (M_Sun)': 1.0,
        'TESS Mag': 10.5,
        'Stellar Distance (pc)': 200
    })
    
    label, probs = predictor.predict_single(features)
    
    print(f"\nğŸ¯ é æ¸¬çµæœ: {label}")
    print(f"\næ©Ÿç‡åˆ†ä½ˆ:")
    for i, class_name in enumerate(predictor.label_encoder.classes_):
        bar = "â–ˆ" * int(probs[i] * 50)
        print(f"  {class_name:20s} {probs[i]:6.2%} {bar}")


def main():
    """ä¸»ç¨‹å¼"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                       â•‘
    â•‘        Exoplanet Model Testing Tool                   â•‘
    â•‘                                                       â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # å°‹æ‰¾æ‰€æœ‰æ¨¡å‹
    model_dir = Path("models")
    model_files = list(model_dir.glob("*.pkl"))
    
    # éæ¿¾æ‰éæ¨¡å‹æª”æ¡ˆ
    model_keywords = ['exoplanet', 'combined', 'transfer', 'lgbm', 'xgb', 'stacking', 
                      'catboost', 'random_forest', 'model', 'new_model']
    model_files = [f for f in model_files if any(keyword in f.name.lower() for keyword in model_keywords)]
    
    if not model_files:
        print("âŒ æ‰¾ä¸åˆ°è¨“ç·´å¥½çš„æ¨¡å‹ï¼")
        print("è«‹å…ˆåŸ·è¡Œè¨“ç·´è…³æœ¬:")
        print("  - python train_with_tess_data.py")
        print("  - python train_custom_model.py")
        print("  - python train_combined_model.py")
        return
    
    # ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹
    latest_model = max(model_files, key=lambda p: p.stat().st_mtime)
    
    # é¡¯ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
    if len(model_files) > 1:
        print("\nå¯ç”¨çš„æ¨¡å‹:")
        for i, model_file in enumerate(sorted(model_files, key=lambda p: p.stat().st_mtime, reverse=True), 1):
            print(f"  {i}. {model_file.name}")
        
        print(f"\né è¨­ä½¿ç”¨æœ€æ–°æ¨¡å‹: {latest_model.name}")
        use_default = input("ä½¿ç”¨é è¨­æ¨¡å‹? (y/n, é è¨­=y): ").strip().lower()
        
        if use_default == 'n':
            choice = input(f"é¸æ“‡æ¨¡å‹ (1-{len(model_files)}): ").strip()
            try:
                idx = int(choice) - 1
                sorted_models = sorted(model_files, key=lambda p: p.stat().st_mtime, reverse=True)
                latest_model = sorted_models[idx]
            except:
                print("ç„¡æ•ˆé¸æ“‡ï¼Œä½¿ç”¨é è¨­æ¨¡å‹")
    
    print(f"\nğŸ“¦ ä½¿ç”¨æ¨¡å‹: {latest_model}")
    
    print("\nè«‹é¸æ“‡æ¸¬è©¦æ¨¡å¼:")
    print("1. æ‰¹æ¬¡æ¸¬è©¦ï¼ˆæ¸¬è©¦æ•´å€‹ CSV æª”æ¡ˆï¼‰")
    print("2. å–®ç­†æ¸¬è©¦ï¼ˆæ¸¬è©¦ç¯„ä¾‹è³‡æ–™ï¼‰")
    print("3. äº’å‹•å¼æ¸¬è©¦ï¼ˆæ‰‹å‹•è¼¸å…¥åƒæ•¸ï¼‰")
    
    choice = input("\nè«‹é¸æ“‡ (1/2/3): ").strip()
    
    if choice == "1":
        test_file = input("è«‹è¼¸å…¥æ¸¬è©¦æª”æ¡ˆè·¯å¾‘ (é è¨­=./tois.csv): ").strip()
        test_file = test_file if test_file else "./tois.csv"
        test_on_file(latest_model, test_file)
    
    elif choice == "2":
        test_single_example(latest_model)
    
    elif choice == "3":
        interactive_test(latest_model)
    
    else:
        print("ç„¡æ•ˆçš„é¸æ“‡ï¼")
    
    print("\n" + "="*60)
    print("âœ… æ¸¬è©¦å®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()