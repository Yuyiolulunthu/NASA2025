"""
ç³»å¤–è¡Œæ˜Ÿè³‡æ–™é›†ä¸‹è¼‰å™¨
æ”¯æ´å¤šå€‹ NASA è³‡æ–™é›†å’Œ Kaggle è³‡æ–™é›†
"""

import requests
import pandas as pd
from pathlib import Path
import json
from datetime import datetime


class ExoplanetDatasetDownloader:
    """ç³»å¤–è¡Œæ˜Ÿè³‡æ–™é›†ä¸‹è¼‰å™¨"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.data_dir.mkdir(exist_ok=True)
        
        # NASA Exoplanet Archive API
        self.nasa_base_url = "https://exoplanetarchive.ipac.caltech.edu/TAP/sync"
        
        # å¯ç”¨çš„è³‡æ–™é›†é…ç½®
        self.datasets = {
            '1_tess_toi': {
                'name': 'TESS Objects of Interest (TOI)',
                'description': 'TESS æœ›é é¡ç™¼ç¾çš„ç³»å¤–è¡Œæ˜Ÿå€™é¸',
                'table': 'toi',
                'size': '~7,700 ç­†',
                'url': 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=TOI',
                'filename': 'tess_toi.csv'
            },
            '2_kepler_koi': {
                'name': 'Kepler Objects of Interest (KOI)',
                'description': 'Kepler æœ›é é¡ç™¼ç¾çš„ç³»å¤–è¡Œæ˜Ÿå€™é¸',
                'table': 'cumulative',
                'size': '~10,000 ç­†',
                'url': 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=cumulative',
                'filename': 'kepler_koi.csv'
            },
            '3_k2_candidates': {
                'name': 'K2 Candidates',
                'description': 'K2 ä»»å‹™ç™¼ç¾çš„ç³»å¤–è¡Œæ˜Ÿå€™é¸',
                'table': 'k2candidates',
                'size': '~1,000 ç­†',
                'url': 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=k2candidates',
                'filename': 'k2_candidates.csv'
            },
            '4_confirmed_planets': {
                'name': 'Confirmed Exoplanets',
                'description': 'æ‰€æœ‰å·²ç¢ºèªçš„ç³»å¤–è¡Œæ˜Ÿï¼ˆç¶œåˆè³‡æ–™ï¼‰',
                'table': 'pscomppars',
                'size': '~5,600+ ç­†',
                'url': 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=PS',
                'filename': 'confirmed_planets.csv'
            },
            '5_extended_catalog': {
                'name': 'Extended Exoplanet Catalog',
                'description': 'æ“´å±•çš„ç³»å¤–è¡Œæ˜Ÿç›®éŒ„',
                'table': 'exoplanets',
                'size': '~5,000+ ç­†',
                'url': 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=exoplanets',
                'filename': 'extended_catalog.csv'
            },
            '6_microlensing': {
                'name': 'Microlensing Planets',
                'description': 'é€éå¾®é‡åŠ›é€é¡ç™¼ç¾çš„ç³»å¤–è¡Œæ˜Ÿ',
                'table': 'microlensing',
                'size': '~200 ç­†',
                'url': 'https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=ML',
                'filename': 'microlensing.csv'
            }
        }
    
    def list_datasets(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è³‡æ–™é›†"""
        print("\n" + "="*70)
        print("ğŸ“Š å¯ç”¨çš„ç³»å¤–è¡Œæ˜Ÿè³‡æ–™é›†")
        print("="*70)
        
        for key, info in self.datasets.items():
            print(f"\n{key}. {info['name']}")
            print(f"   æè¿°: {info['description']}")
            print(f"   å¤§å°: {info['size']}")
            print(f"   æª”æ¡ˆ: {info['filename']}")
    
    def download_from_nasa(self, table_name, filename):
        """å¾ NASA Exoplanet Archive ä¸‹è¼‰è³‡æ–™"""
        print(f"\nğŸ“¥ ä¸‹è¼‰ {table_name} è³‡æ–™...")
        
        # ä½¿ç”¨ CSV æ ¼å¼ä¸‹è¼‰
        query = f"SELECT * FROM {table_name}"
        
        params = {
            'query': query,
            'format': 'csv'
        }
        
        try:
            response = requests.get(self.nasa_base_url, params=params, timeout=60)
            response.raise_for_status()
            
            filepath = self.data_dir / filename
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            # é©—è­‰ä¸‹è¼‰
            df = pd.read_csv(filepath)
            print(f"âœ“ ä¸‹è¼‰æˆåŠŸ: {filepath}")
            print(f"âœ“ è³‡æ–™å½¢ç‹€: {df.shape}")
            print(f"âœ“ æ¬„ä½æ•¸: {len(df.columns)}")
            
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            print("\nğŸ’¡ å‚™ç”¨æ–¹æ¡ˆ: ä½¿ç”¨ç¶²é ä¸‹è¼‰")
            print(f"è«‹è¨ªå•: {self.datasets[list(self.datasets.keys())[0]]['url']}")
            return None
    
    def download_dataset(self, dataset_key):
        """ä¸‹è¼‰æŒ‡å®šçš„è³‡æ–™é›†"""
        if dataset_key not in self.datasets:
            print(f"âŒ æœªçŸ¥çš„è³‡æ–™é›†: {dataset_key}")
            return None
        
        info = self.datasets[dataset_key]
        print(f"\n{'='*70}")
        print(f"æ­£åœ¨ä¸‹è¼‰: {info['name']}")
        print(f"{'='*70}")
        
        filepath = self.download_from_nasa(info['table'], info['filename'])
        
        if filepath:
            # ä¿å­˜å…ƒè³‡æ–™
            metadata = {
                'dataset_name': info['name'],
                'description': info['description'],
                'download_date': datetime.now().isoformat(),
                'filepath': str(filepath),
                'source': 'NASA Exoplanet Archive'
            }
            
            metadata_file = self.data_dir / f"{info['filename']}.meta.json"
            with open(metadata_file, 'w') as f:
                json.dump(metadata, f, indent=2)
        
        return filepath
    
    def download_kaggle_dataset(self):
        """ä¸‹è¼‰ Kaggle ç³»å¤–è¡Œæ˜Ÿè³‡æ–™é›†"""
        print("\n" + "="*70)
        print("ğŸ“¦ Kaggle ç³»å¤–è¡Œæ˜Ÿè³‡æ–™é›†")
        print("="*70)
        
        print("\nå¯ç”¨çš„ Kaggle è³‡æ–™é›†:")
        print("\n1. Kepler Exoplanet Search Results")
        print("   https://www.kaggle.com/datasets/nasa/kepler-exoplanet-search-results")
        print("   - å®Œæ•´çš„ Kepler è³‡æ–™é›†")
        print("   - åŒ…å«ç‰¹å¾µå·¥ç¨‹å¾Œçš„è³‡æ–™")
        
        print("\n2. TESS Exoplanet Candidates")
        print("   https://www.kaggle.com/datasets/quadeer15sh/tess-exoplanet-candidates")
        print("   - TESS è³‡æ–™é›†")
        
        print("\n3. Exoplanet Hunting in Deep Space")
        print("   https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data")
        print("   - æ™‚åºè³‡æ–™ï¼ˆå…‰è®Šæ›²ç·šï¼‰")
        
        print("\nğŸ’¡ å¦‚ä½•ä¸‹è¼‰ Kaggle è³‡æ–™é›†:")
        print("1. å®‰è£ Kaggle CLI: pip install kaggle")
        print("2. è¨­å®š API token: https://www.kaggle.com/docs/api")
        print("3. ä¸‹è¼‰: kaggle datasets download -d nasa/kepler-exoplanet-search-results")
    
    def download_all(self):
        """ä¸‹è¼‰æ‰€æœ‰ NASA è³‡æ–™é›†"""
        print("\né–‹å§‹ä¸‹è¼‰æ‰€æœ‰è³‡æ–™é›†...")
        
        results = {}
        for key in self.datasets.keys():
            filepath = self.download_dataset(key)
            results[key] = filepath
        
        print("\n" + "="*70)
        print("ğŸ“Š ä¸‹è¼‰æ‘˜è¦")
        print("="*70)
        
        for key, filepath in results.items():
            status = "âœ“" if filepath else "âœ—"
            print(f"{status} {self.datasets[key]['name']}: {filepath}")
        
        return results
    
    def create_combined_dataset(self):
        """å»ºç«‹ç¶œåˆè³‡æ–™é›†ï¼ˆåˆä½µå¤šå€‹ä¾†æºï¼‰"""
        print("\n" + "="*70)
        print("ğŸ”— å»ºç«‹ç¶œåˆè³‡æ–™é›†")
        print("="*70)
        
        # é€™è£¡å¯ä»¥å¯¦ä½œå°‡å¤šå€‹è³‡æ–™é›†åˆä½µçš„é‚è¼¯
        # ä¾‹å¦‚ï¼šåˆä½µ TESS, Kepler, K2 çš„è³‡æ–™
        
        print("\nâš ï¸  æ­¤åŠŸèƒ½å°šæœªå¯¦ä½œ")
        print("ğŸ’¡ æç¤º: ä¸åŒè³‡æ–™é›†çš„æ¬„ä½åç¨±å¯èƒ½ä¸åŒï¼Œéœ€è¦ä»”ç´°å°é½Š")


def download_specific_datasets():
    """ä¸‹è¼‰ç‰¹å®šè³‡æ–™é›†çš„ä¾¿æ·æ–¹æ³•"""
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                       â•‘
    â•‘        Exoplanet Dataset Downloader                   â•‘
    â•‘                                                       â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    downloader = ExoplanetDatasetDownloader()
    
    # é¡¯ç¤ºå¯ç”¨è³‡æ–™é›†
    downloader.list_datasets()
    
    # Kaggle è³‡æ–™é›†
    print("\n" + "="*70)
    downloader.download_kaggle_dataset()
    
    print("\n" + "="*70)
    print("è«‹é¸æ“‡æ“ä½œ:")
    print("="*70)
    print("1. ä¸‹è¼‰å–®ä¸€è³‡æ–™é›†")
    print("2. ä¸‹è¼‰æ‰€æœ‰ NASA è³‡æ–™é›†")
    print("3. æŸ¥çœ‹ Kaggle è³‡æ–™é›†è³‡è¨Š")
    print("0. é€€å‡º")
    
    choice = input("\nè«‹é¸æ“‡ (0-3): ").strip()
    
    if choice == '1':
        dataset_key = input("\nè«‹è¼¸å…¥è³‡æ–™é›†ç·¨è™Ÿ (ä¾‹å¦‚: 1_tess_toi): ").strip()
        downloader.download_dataset(dataset_key)
    
    elif choice == '2':
        confirm = input("\nâš ï¸  é€™å°‡ä¸‹è¼‰æ‰€æœ‰è³‡æ–™é›†ï¼Œå¯èƒ½éœ€è¦å¹¾åˆ†é˜ã€‚ç¹¼çºŒ? (y/n): ").strip()
        if confirm.lower() == 'y':
            downloader.download_all()
    
    elif choice == '3':
        downloader.download_kaggle_dataset()
    
    print("\nâœ… å®Œæˆï¼")
    print(f"\nè³‡æ–™å·²å„²å­˜åœ¨: {downloader.data_dir}")


if __name__ == "__main__":
    download_specific_datasets()